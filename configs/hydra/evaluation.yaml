# output paths for hydra logs
run:
  dir: ../scratch/logs/evaluation/runs/${datamodule.key}/${run_name}/${now:%Y-%m-%d}_${now:%H-%M-%S}

sweep:
  dir: ../scratch/logs/evaluation/multiruns/${datamodule.key}/${run_name}/${now:%Y-%m-%d}_${now:%H-%M-%S}
  # subdir: ${hydra.job.num}
  subdir: ${hydra.job.override_dirname}

# you can set here environment variables that are universal for all users
job:
  chdir: True
  env_set:
    CUDA_DEVICE_ORDER: "PCI_BUS_ID"
    HYDRA_FULL_ERROR: "1"
  config:
    override_dirname:
      exclude_keys:
        - ckpt_path
        - datamodule
        - datamodule.batch_size
        - logger.wandb.tags
        - model.optimizer
        - model/optimizer
        - model/scheduler_config
        - model
        - callbacks
        - callbacks.model_checkpoint.monitor
        - callbacks.early_stopping
        - trainer.max_epochs
        - trainer.min_epochs
        - experiment
        - experiment/inference
        - datamodule.mixing_architecture.load
        - model.checkpoint_path
        - datamodule.dataset_parameters.batch_size
        - datamodule.dataset_parameters.num_workers
        - datamodule.datasets.train.seq_min_length
        - datamodule.datasets.train.seq_max_length
        - datamodule.datasets.val.seq_min_length
        - datamodule.datasets.val.seq_max_length
        - datamodule.datasets.test.seq_min_length
        - datamodule.datasets.test.seq_max_length
        - datamodule.x_dim
        - datamodule.y_dim
        - datamodule.phi_dim
        - model.optimizer.lr
        - trainer.accelerator
        - trainer.devices

# Set cuda visible devices from command line: export CUDA_VISIBLE_DEVICES=0;python evaluate_kilt_dataset.py
# Or python run.py +hydra.job.env_set.CUDA_VISIBLE_DEVICES="3'
